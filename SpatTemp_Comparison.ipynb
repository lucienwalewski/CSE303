{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpatTemp_Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXF3V3c-IgIN"
      },
      "source": [
        "# Spatial-Temporal IOU Comparison\n",
        "\n",
        "In this notebook, we use LaeoNet to track faces in selected shots from the Friends dataset which we then compare to the ground truths using Spatial-Temporal IOU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAQscl8gJMvP"
      },
      "source": [
        "## Data Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD-mPTRmJDzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eecb372-3d2c-4afd-cc1d-82172c30813a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0FjVofD79wv"
      },
      "source": [
        "! mkdir data\n",
        "! mkdir data/frames\n",
        "! mkdir data/shots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq_uufI38oPt"
      },
      "source": [
        "## Generating shots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episode_no = 1"
      ],
      "metadata": {
        "id": "l1VoIZ0ByCIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FRAME_PATH = f'drive/MyDrive/Friends/frames/episode{str(episode_no).zfill(2)}.tar.gz'\n",
        "SHOTS_PATH = f'drive/MyDrive/Friends/shots/shots.tar.gz'\n",
        "TRACK_PATH = f'drive/MyDrive/Friends/tracks-features/Friends.pk'\n",
        "VIDEO_PATH = f'drive/MyDrive/Friends_Extra/episode{str(episode_no).zfill(2)}.mp4'"
      ],
      "metadata": {
        "id": "sxKBeMpQzALn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! tar xzf $FRAMES_PATH -C data/frames\n",
        "! tar xzf $SHOTS_PATH -C data"
      ],
      "metadata": {
        "id": "JZSRWOnYy9_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ66JcR38qzx"
      },
      "source": [
        "with open(f'data/shots/season3/episode{str(episode_no).zfill(2)}_shots.txt', 'r') as f:\n",
        "  shots = [(int(l.split(' ')[0]), int(l.split(' ')[1])) for l in f]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hig1Q3Gg9Cgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003ab149-d986-44ef-ccf9-066d99da1d99"
      },
      "source": [
        "from moviepy.editor import *\n",
        "\n",
        "def generate_shots(shots, video, outpath, framerate):\n",
        "  '''Given a list of shot frame intervals and an mp4, \n",
        "  generate the clips'''\n",
        "  clip = VideoFileClip(video)\n",
        "  for i, (start, end) in enumerate(shots):\n",
        "    new_clip = clip.subclip((start-1)/framerate, end/framerate)\n",
        "    new_clip.write_videofile(f'{outpath}shot{i}.mp4', audio = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2899968/45929032 bytes (6.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6356992/45929032 bytes (13.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9601024/45929032 bytes (20.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12967936/45929032 bytes (28.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16252928/45929032 bytes (35.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19587072/45929032 bytes (42.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22716416/45929032 bytes (49.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25812992/45929032 bytes (56.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29253632/45929032 bytes (63.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32612352/45929032 bytes (71.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36249600/45929032 bytes (78.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39395328/45929032 bytes (85.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42500096/45929032 bytes (92.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mY40F1h9lGP",
        "outputId": "2403eaf0-35ac-44d1-b1f9-5ee7e21c5522"
      },
      "source": [
        "# Output mp4 shots to data/shots/\n",
        "generate_shots(shots, VIDEO_PATH, 'data/shots/',23.98)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video data/shots/shot0.mp4\n",
            "[MoviePy] Writing audio in shot0TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126/126 [00:00<00:00, 444.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video data/shots/shot0.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 137/137 [00:06<00:00, 22.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: data/shots/shot0.mp4 \n",
            "\n",
            "[MoviePy] >>>> Building video data/shots/shot1.mp4\n",
            "[MoviePy] Writing audio in shot1TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:00<00:00, 406.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video data/shots/shot1.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 41/41 [00:00<00:00, 73.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: data/shots/shot1.mp4 \n",
            "\n",
            "[MoviePy] >>>> Building video data/shots/shot2.mp4\n",
            "[MoviePy] Writing audio in shot2TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 326/326 [00:00<00:00, 640.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video data/shots/shot2.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 354/354 [00:18<00:00, 18.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: data/shots/shot2.mp4 \n",
            "\n",
            "[MoviePy] >>>> Building video data/shots/shot3.mp4\n",
            "[MoviePy] Writing audio in shot3TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:00<00:00, 368.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video data/shots/shot3.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 42/42 [00:00<00:00, 75.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: data/shots/shot3.mp4 \n",
            "\n",
            "[MoviePy] >>>> Building video data/shots/shot4.mp4\n",
            "[MoviePy] Writing audio in shot4TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 572.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video data/shots/shot4.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 245/245 [00:12<00:00, 18.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: data/shots/shot4.mp4 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpzjuL5EJ46k"
      },
      "source": [
        "## Downloading LaeoNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e13N_gNJnQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656ccd27-53c2-4681-a43b-242f922f97a1"
      },
      "source": [
        "!wget https://github.com/AVAuco/laeonetplus/archive/refs/heads/main.zip -O main.zip\n",
        "!unzip main.zip\n",
        "!ln -s laeonetplus-mjmarin-demotrack laeonetplus-main"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-11 18:06:15--  https://github.com/AVAuco/laeonetplus/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/AVAuco/laeonetplus/zip/refs/heads/main [following]\n",
            "--2021-12-11 18:06:16--  https://codeload.github.com/AVAuco/laeonetplus/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [           <=>      ] 106.06M  16.3MB/s    in 7.2s    \n",
            "\n",
            "2021-12-11 18:06:23 (14.7 MB/s) - ‘main.zip’ saved [111209738]\n",
            "\n",
            "Archive:  main.zip\n",
            "e7fb7a977a84d63cf524e59e9716ffa7fd42cb72\n",
            "   creating: laeonetplus-main/\n",
            "  inflating: laeonetplus-main/.gitignore  \n",
            "  inflating: laeonetplus-main/LAEOnetplus.png  \n",
            "  inflating: laeonetplus-main/README.md  \n",
            "   creating: laeonetplus-main/data/\n",
            "   creating: laeonetplus-main/data/ava_clips/\n",
            "  inflating: laeonetplus-main/data/ava_clips/9Y_l9NsnYE0_01323.mp4  \n",
            "   creating: laeonetplus-main/data/ava_val_crop/\n",
            "  inflating: laeonetplus-main/data/ava_val_crop/7T5G0CmwTPo_00936_0000_pair_20_19.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/7T5G0CmwTPo_00936_0000_pair_20_19_map.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/914yZXz-iRs_01549_0000_pair_192_194.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/914yZXz-iRs_01549_0000_pair_192_194_map.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/914yZXz-iRs_01569_0000_pair_196_195.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/914yZXz-iRs_01569_0000_pair_196_195_map.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/SCh-ZImnyyk_00902_0000_pair_1_0.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/SCh-ZImnyyk_00902_0000_pair_1_0_map.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/covMYDBa5dk_01024_0000_pair_37_35.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/covMYDBa5dk_01024_0000_pair_37_35_map.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/om_83F5VwTQ_01187_0000_pair_51_49.jpg  \n",
            "  inflating: laeonetplus-main/data/ava_val_crop/om_83F5VwTQ_01187_0000_pair_51_49_map.jpg  \n",
            "  inflating: laeonetplus-main/data/avalaeo_samplist_train.h5  \n",
            "  inflating: laeonetplus-main/data/avalaeo_samplist_val.h5  \n",
            "   creating: laeonetplus-main/data/tvhid/\n",
            "  inflating: laeonetplus-main/data/tvhid/highFive_0016.avi  \n",
            "   creating: laeonetplus-main/datasets/\n",
            "  inflating: laeonetplus-main/datasets/ln_aflwDataset.py  \n",
            "  inflating: laeonetplus-main/datasets/ln_avagoogleConfig.py  \n",
            "  inflating: laeonetplus-main/datasets/ln_avagoogleImages.py  \n",
            "  inflating: laeonetplus-main/datasets/ln_avagoogleLAEOAnnotations.py  \n",
            "  inflating: laeonetplus-main/datasets/ln_ucolaeoConfig.py  \n",
            "   creating: laeonetplus-main/doc/\n",
            "  inflating: laeonetplus-main/doc/dependencies.md  \n",
            "  inflating: laeonetplus-main/doc/fr_sh000_p0_2_008.jpg  \n",
            "  inflating: laeonetplus-main/doc/training.md  \n",
            "   creating: laeonetplus-main/mains/\n",
            "  inflating: laeonetplus-main/mains/ln_demo_test.py  \n",
            "   creating: laeonetplus-main/models/\n",
            "   creating: laeonetplus-main/models/bestAVA/\n",
            "  inflating: laeonetplus-main/models/bestAVA/model-hmaps-trava_pyv36.hdf5  \n",
            "  inflating: laeonetplus-main/models/bestAVA/model-hmaps-trava_weights.h5  \n",
            "   creating: laeonetplus-main/models/bestUCO/\n",
            "  inflating: laeonetplus-main/models/bestUCO/model-hmaps-truco_pyv36.hdf5  \n",
            "  inflating: laeonetplus-main/models/bestUCO/model-hmaps-truco_weights.h5  \n",
            "  inflating: laeonetplus-main/models/meanmaps10.npy  \n",
            "  inflating: laeonetplus-main/models/model-init-ssheadbranch.json  \n",
            "  inflating: laeonetplus-main/models/model-init-ssheadbranch_py35.hdf5  \n",
            "  inflating: laeonetplus-main/models/model-init-ssheadbranch_py36.hdf5  \n",
            "  inflating: laeonetplus-main/models/model-init-ssheadbranch_w.hdf5  \n",
            "  inflating: laeonetplus-main/requirements.txt  \n",
            "   creating: laeonetplus-main/tracking/\n",
            "   creating: laeonetplus-main/tracking/data/\n",
            "   creating: laeonetplus-main/tracking/data/models/\n",
            "   creating: laeonetplus-main/tracking/data/models/detector/\n",
            "  inflating: laeonetplus-main/tracking/data/models/detector/download_model_py3.6.sh  \n",
            "   creating: laeonetplus-main/tracking/detector/\n",
            " extracting: laeonetplus-main/tracking/detector/__init__.py  \n",
            "   creating: laeonetplus-main/tracking/detector/bounding_box_utils/\n",
            " extracting: laeonetplus-main/tracking/detector/bounding_box_utils/__init__.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/bounding_box_utils/bounding_box_utils.py  \n",
            "   creating: laeonetplus-main/tracking/detector/keras_layers/\n",
            " extracting: laeonetplus-main/tracking/detector/keras_layers/__init__.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/keras_layers/keras_layer_AnchorBoxes.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/keras_layers/keras_layer_DecodeDetections.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/keras_layers/keras_layer_DecodeDetectionsFast.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/keras_layers/keras_layer_L2Normalization.py  \n",
            "   creating: laeonetplus-main/tracking/detector/keras_loss_function/\n",
            " extracting: laeonetplus-main/tracking/detector/keras_loss_function/__init__.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/keras_loss_function/keras_ssd_loss.py  \n",
            "   creating: laeonetplus-main/tracking/detector/models/\n",
            " extracting: laeonetplus-main/tracking/detector/models/__init__.py  \n",
            "  inflating: laeonetplus-main/tracking/detector/models/keras_ssd512.py  \n",
            "  inflating: laeonetplus-main/tracking/ln_tracking_heads.py  \n",
            "  inflating: laeonetplus-main/tracking/tube_utils.py  \n",
            "   creating: laeonetplus-main/tracking/utilstr/\n",
            " extracting: laeonetplus-main/tracking/utilstr/__init__.py  \n",
            "  inflating: laeonetplus-main/tracking/utilstr/utils.py  \n",
            "   creating: laeonetplus-main/train/\n",
            "  inflating: laeonetplus-main/train/ln_dataGeneratorAVALAEO.py  \n",
            "  inflating: laeonetplus-main/train/ln_dataGeneratorLAEOhgfm.py  \n",
            "  inflating: laeonetplus-main/train/ln_dataGeneratorLAEOsyn.py  \n",
            "  inflating: laeonetplus-main/train/ln_train3DconvModelGeomMBranchCropMapAVA.py  \n",
            "  inflating: laeonetplus-main/train/ln_trainingUtils.py  \n",
            "   creating: laeonetplus-main/utils/\n",
            "  inflating: laeonetplus-main/utils/ln_laeoImage.py  \n",
            "  inflating: laeonetplus-main/utils/ln_laeoNets.py  \n",
            "  inflating: laeonetplus-main/utils/ln_model_utils.py  \n",
            "  inflating: laeonetplus-main/utils/ln_netUtils.py  \n",
            "  inflating: laeonetplus-main/utils/mj_dataHelper.py  \n",
            "  inflating: laeonetplus-main/utils/mj_genericUtils.py  \n",
            "  inflating: laeonetplus-main/utils/mj_inflateMeans.py  \n",
            "  inflating: laeonetplus-main/utils/mj_laeoUtils.py  \n",
            "  inflating: laeonetplus-main/utils/mj_miningSamples.py  \n",
            "  inflating: laeonetplus-main/utils/mj_tracksManager.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to the correct directory\n",
        "!ls\n",
        "%cd laeonetplus-main\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV3hKSczrQdv",
        "outputId": "c27c506b-1c8a-45ac-f0a9-eb620b0efd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  drive  laeonetplus-main  main.zip  sample_data\n",
            "/content/laeonetplus-main\n",
            "/content/laeonetplus-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHPypFLqKPjE"
      },
      "source": [
        "## Loading LaeoNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySIQzyKSHIpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f2a920-ad43-4406-b9c3-dbd0600d899c"
      },
      "source": [
        "\"\"\"\n",
        "Demo code for testing a trained model on an input video.\n",
        "Adpted to Google Colab\n",
        " \n",
        "Reference:\n",
        "MJ. Marin-Jimenez, V. Kalogeiton, P. Medina-Suarez, A. Zisserman\n",
        "LAEO-Net++: revisiting people Looking At Each Other in videos\n",
        "IEEE TPAMI, 2021\n",
        " \n",
        "(c) MJMJ/2021\n",
        "\"\"\"\n",
        " \n",
        "import os, sys\n",
        "import numpy as np\n",
        "import cv2\n",
        " \n",
        "from os.path import expanduser\n",
        "import os.path as osp\n",
        "import pickle\n",
        " \n",
        "homedir = \"/content/laeonetplus-main/\"\n",
        " \n",
        "mainsdir = osp.join(homedir, \"mains\")\n",
        " \n",
        "# Add custom directories with source code\n",
        "sys.path.insert(0, os.path.join(mainsdir,\"../tracking\")) # CHANGE ME\n",
        "sys.path.insert(0, os.path.join(mainsdir,\"../utils\")) # CHANGE ME\n",
        "sys.path.insert(0, os.path.join(mainsdir,\"../datasets\")) # CHANGE ME\n",
        " \n",
        "sys.path.insert(0, os.path.join(homedir,\"utils\")) # CHANGE ME\n",
        "sys.path.insert(0, os.path.join(homedir,\"datasets\")) # CHANGE ME\n",
        "sys.path.insert(0, os.path.join(homedir,\"tracking\")) # CHANGE ME\n",
        " \n",
        " \n",
        "gpu_rate = 0.30\n",
        "theSEED = 0\n",
        " \n",
        " \n",
        "# for reproducibility\n",
        "np.random.seed(theSEED)\n",
        " \n",
        "from mj_tracksManager import TracksManager\n",
        "from ln_avagoogleImages import mj_getImagePairSeqFromTracks, mj_getFrameBBsPairFromTracks\n",
        "from ln_laeoImage import mj_padImageTrack\n",
        "from ln_tracking_heads import process_video\n",
        " \n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/laeonetplus-main/tracking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjZtOZ7I-fip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "a80a4c7f-d96e-4e69-e42b-401af210c63b"
      },
      "source": [
        "# ====================================================================================\n",
        " \n",
        "modeldir = homedir+\"/models/bestAVA\"\n",
        "modelfile = os.path.join(modeldir, \"model-hmaps-trava_pyv36.hdf5\")\n",
        " \n",
        "outdirbase = homedir+\"/results\"\n",
        " \n",
        "case_wanted = \"val\"\n",
        "inputs = \"1010\"\n",
        "  \n",
        "# Load model\n",
        "model = load_model(modelfile, compile=False)\n",
        "model.summary()\n",
        " \n",
        "# Load mean map (mean head is not used for LAEO-Net++)\n",
        "meanfile = os.path.join(homedir, \"models\", \"meanmaps10.npy\")\n",
        "mean_map_ = np.load(meanfile)\n",
        "mean_map5 = mean_map_[5*64:6*64,]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f976316cbd94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mmj_l2normalize\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Unless required by applicable law or agreed to in writing, software\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;31m# distributed under the License is distributed on an \"AS IS\" BASIS,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: Exception encountered when calling layer \"ml2norm\" (type Lambda).\n\nname 'K' is not defined\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 48), dtype=float32)\n  • mask=None\n  • training=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9f3SONx-7wj"
      },
      "source": [
        "## Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ridI7t-4nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466820d3-ff24-4301-b070-2fc8637be4c6"
      },
      "source": [
        "# Some parameters\n",
        "verbose = 1\n",
        "save_to_disk = True \n",
        "   \n",
        "lTracksInShots = []\n",
        " \n",
        "# Prepare data\n",
        "# =================================\n",
        "videonames = [f\"shot{i}\" for i in range(5)]\n",
        "for videoname in videonames:\n",
        "  videospath = \"data/shots/\"\n",
        "  videopath = os.path.join(videospath, videoname+\".mp4\")\n",
        "\n",
        "  framesdir_for_detection = \"/tmp/\"+videoname+\"_frames\"\n",
        "\n",
        "  outdir= os.path.join(outdirbase, videoname+\"_laeo\") \n",
        "  \n",
        "  # Given video, detect heads and generate tracks\n",
        "  # ===============================\n",
        "  tracks_live = process_video(videopath, verbose=verbose, framesdir=framesdir_for_detection)\n",
        "  tm2 = TracksManager(filepath=\"\", data=tracks_live)\n",
        "  \n",
        "  lTracksInShots.append(tm2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video data/shots/shot0.mp4\n",
            "Detections not found for video data/shots/shot0.mp4, generating...\n",
            "Downloading model...\n",
            "Model downloaded to /content/laeonetplus-main/tracking/utilstr/../data/models/detector/ssd512-hollywood-trainval-bs_16-lr_1e-05-scale_pascal-epoch-187-py3.6.h5.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "Could not open input video file data/shots/shot0.mp4\n",
            "Reading video file data/shots/shot0.mp4\n",
            "Detections saved to \"/content/laeonetplus-main/tracking/utilstr/../data/results/dets/shot0_processed_th0.2.pkl/\"\n",
            "Linking backwards\n",
            "Linking forwards\n",
            "Finished processing tracks for video data/shots/shot0.mp4, now saving..\n",
            "Processing video data/shots/shot1.mp4\n",
            "Detections not found for video data/shots/shot1.mp4, generating...\n",
            "Could not open input video file data/shots/shot1.mp4\n",
            "Reading video file data/shots/shot1.mp4\n",
            "Detections saved to \"/content/laeonetplus-main/tracking/utilstr/../data/results/dets/shot1_processed_th0.2.pkl/\"\n",
            "Linking backwards\n",
            "Linking forwards\n",
            "Finished processing tracks for video data/shots/shot1.mp4, now saving..\n",
            "Processing video data/shots/shot2.mp4\n",
            "Detections not found for video data/shots/shot2.mp4, generating...\n",
            "Could not open input video file data/shots/shot2.mp4\n",
            "Reading video file data/shots/shot2.mp4\n",
            "Detections saved to \"/content/laeonetplus-main/tracking/utilstr/../data/results/dets/shot2_processed_th0.2.pkl/\"\n",
            "Linking backwards\n",
            "Linking forwards\n",
            "Finished processing tracks for video data/shots/shot2.mp4, now saving..\n",
            "Processing video data/shots/shot3.mp4\n",
            "Detections not found for video data/shots/shot3.mp4, generating...\n",
            "Could not open input video file data/shots/shot3.mp4\n",
            "Reading video file data/shots/shot3.mp4\n",
            "Detections saved to \"/content/laeonetplus-main/tracking/utilstr/../data/results/dets/shot3_processed_th0.2.pkl/\"\n",
            "Linking backwards\n",
            "Linking forwards\n",
            "Finished processing tracks for video data/shots/shot3.mp4, now saving..\n",
            "Processing video data/shots/shot4.mp4\n",
            "Detections not found for video data/shots/shot4.mp4, generating...\n",
            "Could not open input video file data/shots/shot4.mp4\n",
            "Reading video file data/shots/shot4.mp4\n",
            "Detections saved to \"/content/laeonetplus-main/tracking/utilstr/../data/results/dets/shot4_processed_th0.2.pkl/\"\n",
            "Linking backwards\n",
            "Linking forwards\n",
            "Finished processing tracks for video data/shots/shot4.mp4, now saving..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YQHNggrfXw1"
      },
      "source": [
        "detections = [[i for i in range(lTracksInShots[s].ntracks)] for s in range(len(shots))]\n",
        "\n",
        "for s in range(len(shots)):\n",
        "  t = lTracksInShots[s]\n",
        "  starting_frame, ending_frame = np.empty(t.ntracks), np.empty(t.ntracks)\n",
        "  bbx = np.empty(t.ntracks)\n",
        "\n",
        "  for trix in range(0, t.ntracks):\n",
        "    start, end = int(t.start(trix)), int(t.end(trix))\n",
        "    bbx = (t.getTrackIntervalBBs(trix, start, end))\n",
        "\n",
        "    detections[s][trix] = np.concatenate((np.arange(start, end + 1, dtype = 'int').reshape((-1, 1)), \n",
        "                                          bbx), axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9DiyugtTQVz"
      },
      "source": [
        "# Extracting Ground Truth Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# go back to original directory\n",
        "% cd -"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baxiox4TuiX3",
        "outputId": "96dd6cf7-d4b2-49f7-8a8b-6b1c99ec7f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTWdJBIkTUOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "e1e8fca4-ad1c-4af8-975c-69be7aea16dc"
      },
      "source": [
        "with open(TRACK_PATH, 'rb') as f:\n",
        "  tracks = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-a4a736a9a84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRACK_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS2fJKKsUM1G"
      },
      "source": [
        "ground_truth = [[] for i in range(len(shots))]\n",
        "\n",
        "tracks_res = [{} for _ in range(len(shots))]\n",
        "for trackid, vals in tracks['episode01']['face'].items():\n",
        "\n",
        "    shot_id = -1\n",
        "    for i in range(len(shots)):\n",
        "      if shots[i][0] <= vals[0,0] <= shots[i][1]:\n",
        "        shot_id = i\n",
        "        tracks_res[shot_id][trackid] = []\n",
        "\n",
        "    if shot_id >= 0:\n",
        "      for frame, bbx1, bbx2, bbx3, bbx4 in vals:\n",
        "        start_frame = shots[shot_id][0]\n",
        "        tracks_res[shot_id][trackid].append(np.array([int(frame) - start_frame, bbx1, bbx2, bbx3, bbx4]))\n",
        "  \n",
        "for s in range(len(shots)):\n",
        "  for items in tracks_res[s].values():\n",
        "    to_add = [items[0]]\n",
        "    for i in range(1, len(items)):\n",
        "      if items[i][0] - items[i - 1][0] > 1:\n",
        "        ground_truth[s].append(to_add)\n",
        "        to_add = []\n",
        "      to_add.append(items[i])\n",
        "    ground_truth[s].append(to_add)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE-iPgNZvaq9",
        "outputId": "df1e69b2-f633-420b-abcd-27d2239542c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  drive  laeonetplus-main  main.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFp8XPuyRzJ4"
      },
      "source": [
        "# Computing the Spatial and Spatio-Temporal IOUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6DFbA2L1wcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def2fb96-36f9-4aa2-a17c-7d4d14285e79"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/vkalogeiton/caffe/act-detector/act-detector-scripts/ACT_utils.py -O ACT_utils.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-11 18:25:07--  https://raw.githubusercontent.com/vkalogeiton/caffe/act-detector/act-detector-scripts/ACT_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5791 (5.7K) [text/plain]\n",
            "Saving to: ‘ACT_utils.py’\n",
            "\n",
            "\rACT_utils.py          0%[                    ]       0  --.-KB/s               \rACT_utils.py        100%[===================>]   5.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-11 18:25:07 (45.4 MB/s) - ‘ACT_utils.py’ saved [5791/5791]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLXVzJH6vewm",
        "outputId": "b8090db9-4fc3-408a-c0ee-d8bb90c1e06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACT_utils.py  \u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34mlaeonetplus-main\u001b[0m/  main.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyh5UG5X13l1"
      },
      "source": [
        "from ACT_utils import iou3dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72V_Qbdqn9-3"
      },
      "source": [
        "for i in range(len(ground_truth)):\n",
        "  for j in range(len(ground_truth[i])):\n",
        "    ground_truth[i][j] = np.array(ground_truth[i][j])\n",
        "  ground_truth[i] = np.array(ground_truth[i])\n",
        "\n",
        "for i in range(len(detections)):\n",
        "  for j in range(len(detections[i])):\n",
        "    detections[i][j] = np.array(detections[i][j])\n",
        "  detections[i] = np.array(detections[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsG8EiQe8tsi"
      },
      "source": [
        "similarity_temporal_spatial = [np.empty((len(ground_truth[s]), len(detections[s]))) for s in range(len(shots))]\n",
        "similarity_spatial = [np.empty((len(ground_truth[s]), len(detections[s]))) for s in range(len(shots))]\n",
        "\n",
        "for s in range(len(shots)):\n",
        "  for i in range(len(ground_truth[s])):\n",
        "    for j in range(len(detections[s])):\n",
        "      similarity_temporal_spatial[s][i][j] = iou3dt(ground_truth[s][i], detections[s][j])\n",
        "      similarity_spatial[s][i][j] = iou3dt(ground_truth[s][i], detections[s][j], True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uv073QJaX8"
      },
      "source": [
        "from numpy import unravel_index\n",
        "import copy\n",
        "\n",
        "def match(arr):\n",
        "  similarity = copy.deepcopy(arr)\n",
        "  matched = [[] for _ in range(len(similarity))]\n",
        "  for s in range(len(similarity)):\n",
        "    while (np.count_nonzero(similarity[s])) > 0:\n",
        "      max_score = np.amax(similarity[s])\n",
        "      i, j = unravel_index(similarity[s].argmax(), similarity[s].shape)\n",
        "      matched[s].append((i, j, max_score))\n",
        "      similarity[s][:,j] = 0\n",
        "  return matched"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqPjZzqMLCZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeadbd01-45a8-4792-cc72-a17591693dc2"
      },
      "source": [
        "len(match(similarity_spatial)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vng8h3ZkMIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c101b19-f0da-44be-b3d2-feaf590fc1b1"
      },
      "source": [
        "match(similarity_temporal_spatial)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Os6CfCOenSig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}